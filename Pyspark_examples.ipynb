{"cells":[{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Load training data\ntraining = spark.read.format(\"libsvm\").load(\"/FileStore/tables/sample_libsvm_data.txt\")\n\nlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n\n# Fit the model\nlrModel = lr.fit(training)\n\n# Print the coefficients and intercept for logistic regression\nprint(\"Coefficients: \" + str(lrModel.coefficients))\nprint(\"Intercept: \" + str(lrModel.intercept))\n\n# We can also use the multinomial family for binary classification\nmlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n\n# Fit the model\nmlrModel = mlr.fit(training)\n\n# Print the coefficients and intercepts for logistic regression with multinomial family\nprint(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\nprint(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: (692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.35398352419e-05,-9.10273850559e-05,-0.000194674305469,-0.000203006424735,-3.14761833149e-05,-6.84297760266e-05,1.58836268982e-05,1.40234970914e-05,0.00035432047525,0.000114432728982,0.000100167123837,0.00060141093038,0.000284024817912,-0.000115410847365,0.000385996886313,0.000635019557424,-0.000115064123846,-0.00015271865865,0.000280493380899,0.000607011747119,-0.000200845966325,-0.000142107557929,0.000273901034116,0.00027730456245,-9.83802702727e-05,-0.000380852244352,-0.000253151980086,0.000277477147708,-0.000244361976392,-0.00153947446876,-0.000230733284113])\nIntercept: 0.22456315961250298\nMultinomial coefficients: 2 X 692 CSRMatrix\n(0,244) 0.0\n(0,263) 0.0001\n(0,272) 0.0001\n(0,300) 0.0001\n(0,350) -0.0\n(0,351) -0.0\n(0,378) -0.0\n(0,379) -0.0\n(0,405) -0.0\n(0,406) -0.0006\n(0,407) -0.0001\n(0,428) 0.0001\n(0,433) -0.0\n(0,434) -0.0007\n(0,455) 0.0001\n(0,456) 0.0001\n..\n..\nMultinomial intercepts: [-0.120658794459,0.120658794459]\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Load and parse the data file, converting it to a DataFrame.\ndata = spark.read.format(\"libsvm\").load(\"/FileStore/tables/sample_libsvm_data.txt\")\n\n# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n\n# Automatically identify categorical features, and index them.\n# Set maxCategories so features with > 4 distinct values are treated as continuous.\nfeatureIndexer =\\\n    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Split the data into training and test sets (30% held out for testing)\n(trainingData, testData) = data.randomSplit([0.7, 0.3])\n\n# Train a RandomForest model.\nrf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Convert indexed labels back to original labels.\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n                               labels=labelIndexer.labels)\n\n# Chain indexers and forest in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n\n# Train model.  This also runs the indexers.\nmodel = pipeline.fit(trainingData)\n\n# Make predictions.\npredictions = model.transform(testData)\n\n# Select example rows to display.\npredictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+-----+--------------------+\npredictedLabel|label|            features|\n+--------------+-----+--------------------+\n           0.0|  0.0|(692,[121,122,123...|\n           0.0|  0.0|(692,[122,123,124...|\n           0.0|  0.0|(692,[123,124,125...|\n           0.0|  0.0|(692,[123,124,125...|\n           0.0|  0.0|(692,[124,125,126...|\n+--------------+-----+--------------------+\nonly showing top 5 rows\n\nTest Error = 0.0277778\nRandomForestClassificationModel (uid=RandomForestClassifier_fc6ec09273ac) with 10 trees\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["rfModel = model.stages[2]\nprint(rfModel)  # summary only"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">RandomForestClassificationModel (uid=RandomForestClassifier_fc6ec09273ac) with 10 trees\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6}],"metadata":{"name":"Pyspark_examples","notebookId":1060701999630622},"nbformat":4,"nbformat_minor":0}
